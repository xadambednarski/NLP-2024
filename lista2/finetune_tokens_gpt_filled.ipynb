{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, GPT2ForTokenClassification, DataCollatorWithPadding, Trainer, TrainingArguments, pipeline\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def label_words(data):\n",
    "    text = data['text']\n",
    "    labels = data['label']\n",
    "    \n",
    "    words = []\n",
    "    start = 0\n",
    "    for match in re.finditer(r'\\S+', text):\n",
    "        word = match.group()\n",
    "        word_start = match.start()\n",
    "        word_end = match.end()\n",
    "        words.append({\n",
    "            'word': word,\n",
    "            'start': word_start,\n",
    "            'end': word_end\n",
    "        })\n",
    "\n",
    "    labeled_words = []\n",
    "    for word_info in words:\n",
    "        word_label = \"Neutralna\"\n",
    "        for start_idx, end_idx, label in labels:\n",
    "            if word_info['start'] >= start_idx and word_info['end'] <= end_idx:\n",
    "                word_label = label\n",
    "        labeled_words.append({\n",
    "            'word': word_info['word'],\n",
    "            'label': word_label\n",
    "        })\n",
    "\n",
    "    return labeled_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf20608895a485898002750982b8e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20caba892754034a9f4921a228a57f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 1078\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 60\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"train\": \"train_filled.jsonl\", \"test\": \"test.jsonl\"}\n",
    "dataset = load_dataset(\"./tokens\", data_files=data_files)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for sentence in dataset[\"train\"][\"labels\"]:\n",
    "    labels += sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels = sorted(list(set(labels)))\n",
    "label2id = dict(zip(sorted_labels, range(0, len(sorted_labels))))\n",
    "id2label = dict(zip(range(0, len(sorted_labels)), sorted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at sdadas/polish-gpt2-medium and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sdadas/polish-gpt2-medium\", add_prefix_space=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2ForTokenClassification.from_pretrained(\"sdadas/polish-gpt2-medium\",\n",
    "                                                        num_labels=len(label2id),\n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label=id2label)\n",
    "\n",
    "classifier = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(data, tokenizer, label_map):\n",
    "    tokenized_data = []\n",
    "    \n",
    "    for entry in data:\n",
    "        tokens = tokenizer(\n",
    "            entry[\"text\"],\n",
    "            is_split_into_words=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "        )\n",
    "        word_ids = tokens.word_ids()\n",
    "        labels = []\n",
    "        \n",
    "        for word_id in word_ids:\n",
    "            if word_id is None or word_id == tokenizer.eos_token_id:\n",
    "                labels.append(-100)\n",
    "            else:\n",
    "                labels.append(label_map[entry[\"labels\"][word_id]])\n",
    "        \n",
    "        tokens[\"labels\"] = labels\n",
    "        tokenized_data.append(tokens)\n",
    "    \n",
    "    return tokenized_data\n",
    "\n",
    "processed_data_train = tokenize_and_align_labels(dataset[\"train\"], tokenizer, label2id)\n",
    "processed_data_test = tokenize_and_align_labels(dataset[\"test\"], tokenizer, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForTokenClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(51200, 1024)\n",
      "    (wpe): Embedding(2048, 1024)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): lora.Linear(\n",
      "            (base_layer): Conv1D(nf=3072, nx=1024)\n",
      "            (lora_dropout): ModuleDict(\n",
      "              (default): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (lora_A): ModuleDict(\n",
      "              (default): Linear(in_features=1024, out_features=64, bias=False)\n",
      "            )\n",
      "            (lora_B): ModuleDict(\n",
      "              (default): Linear(in_features=64, out_features=3072, bias=False)\n",
      "            )\n",
      "            (lora_embedding_A): ParameterDict()\n",
      "            (lora_embedding_B): ParameterDict()\n",
      "            (lora_magnitude_vector): ModuleDict()\n",
      "          )\n",
      "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
      "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
      "          (act): FastGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): ModulesToSaveWrapper(\n",
      "    (original_module): Linear(in_features=1024, out_features=6, bias=True)\n",
      "    (modules_to_save): ModuleDict(\n",
      "      (default): Linear(in_features=1024, out_features=6, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukasz/miniconda3/envs/nlp/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS, r=64, lora_alpha=1, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "print(peft_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5664ff685b3a4a60a905c749f3009436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2555025eb8f49ea90d16ab762f29fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05110986903309822, 'eval_accuracy': 21.536458333333332, 'eval_runtime': 0.9944, 'eval_samples_per_second': 60.337, 'eval_steps_per_second': 15.084, 'epoch': 1.0}\n",
      "{'loss': 0.0953, 'grad_norm': 0.3646955192089081, 'learning_rate': 0.0008765432098765433, 'epoch': 1.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194cfd3c69a646bda8eae16fdf5e2305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09211921691894531, 'eval_accuracy': 21.3671875, 'eval_runtime': 1.0504, 'eval_samples_per_second': 57.12, 'eval_steps_per_second': 14.28, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accbfbdf96d04bc696c02ff846040b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08411039412021637, 'eval_accuracy': 21.484375, 'eval_runtime': 1.0397, 'eval_samples_per_second': 57.706, 'eval_steps_per_second': 14.427, 'epoch': 3.0}\n",
      "{'loss': 0.0578, 'grad_norm': 0.3573233187198639, 'learning_rate': 0.0007530864197530865, 'epoch': 3.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cf8e7e76e24fea8eece27f80f88d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11131899058818817, 'eval_accuracy': 21.3671875, 'eval_runtime': 1.0404, 'eval_samples_per_second': 57.669, 'eval_steps_per_second': 14.417, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8652239ff52b4e04b270f830cbbf4587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1385037750005722, 'eval_accuracy': 21.276041666666668, 'eval_runtime': 1.0426, 'eval_samples_per_second': 57.549, 'eval_steps_per_second': 14.387, 'epoch': 5.0}\n",
      "{'loss': 0.0547, 'grad_norm': 0.024033259600400925, 'learning_rate': 0.0006296296296296296, 'epoch': 5.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a48b8858de43ee8a04db7d7b37a5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1490623503923416, 'eval_accuracy': 21.302083333333332, 'eval_runtime': 1.0444, 'eval_samples_per_second': 57.451, 'eval_steps_per_second': 14.363, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b943e162d92e44bf9b38182889c48b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12243536114692688, 'eval_accuracy': 21.3671875, 'eval_runtime': 1.0498, 'eval_samples_per_second': 57.152, 'eval_steps_per_second': 14.288, 'epoch': 7.0}\n",
      "{'loss': 0.0463, 'grad_norm': 0.05410575866699219, 'learning_rate': 0.0005061728395061728, 'epoch': 7.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95729a409084b5db67b167dec7f2e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18335968255996704, 'eval_accuracy': 21.302083333333332, 'eval_runtime': 1.0521, 'eval_samples_per_second': 57.029, 'eval_steps_per_second': 14.257, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d0d94442e3409f84b03bf88cae4601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19152198731899261, 'eval_accuracy': 21.315104166666668, 'eval_runtime': 1.0419, 'eval_samples_per_second': 57.587, 'eval_steps_per_second': 14.397, 'epoch': 9.0}\n",
      "{'loss': 0.0425, 'grad_norm': 0.026814542710781097, 'learning_rate': 0.00038271604938271603, 'epoch': 9.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0377bfaa139547a3b7db1df0369f71e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19353152811527252, 'eval_accuracy': 21.276041666666668, 'eval_runtime': 1.0482, 'eval_samples_per_second': 57.241, 'eval_steps_per_second': 14.31, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb22bd2e7ef498c8a385c89901271ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1877882480621338, 'eval_accuracy': 21.276041666666668, 'eval_runtime': 1.0346, 'eval_samples_per_second': 57.993, 'eval_steps_per_second': 14.498, 'epoch': 11.0}\n",
      "{'loss': 0.0424, 'grad_norm': 0.02487647905945778, 'learning_rate': 0.00025925925925925926, 'epoch': 11.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22817eddad149b5abf71bf457f161ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20605230331420898, 'eval_accuracy': 21.276041666666668, 'eval_runtime': 1.0333, 'eval_samples_per_second': 58.067, 'eval_steps_per_second': 14.517, 'epoch': 12.0}\n",
      "{'loss': 0.0337, 'grad_norm': 0.2072771042585373, 'learning_rate': 0.00013580246913580247, 'epoch': 12.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d427584c51e41d49c9ab6b1072f514e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2011784464120865, 'eval_accuracy': 21.315104166666668, 'eval_runtime': 1.0315, 'eval_samples_per_second': 58.169, 'eval_steps_per_second': 14.542, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb6e4087c86417ab7314d6db1ea0c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20462816953659058, 'eval_accuracy': 21.315104166666668, 'eval_runtime': 1.0529, 'eval_samples_per_second': 56.988, 'eval_steps_per_second': 14.247, 'epoch': 14.0}\n",
      "{'loss': 0.0372, 'grad_norm': 0.041078075766563416, 'learning_rate': 1.2345679012345678e-05, 'epoch': 14.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a697b6f4b21c4659b6febf310e83f3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2070254683494568, 'eval_accuracy': 21.315104166666668, 'eval_runtime': 1.0488, 'eval_samples_per_second': 57.208, 'eval_steps_per_second': 14.302, 'epoch': 15.0}\n",
      "{'train_runtime': 676.9515, 'train_samples_per_second': 23.886, 'train_steps_per_second': 5.983, 'train_loss': 0.051088215068534566, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4050, training_loss=0.051088215068534566, metrics={'train_runtime': 676.9515, 'train_samples_per_second': 23.886, 'train_steps_per_second': 5.983, 'total_flos': 3832556129740800.0, 'train_loss': 0.051088215068534566, 'epoch': 15.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()*100}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"gpt2-token-clf\",\n",
    "        learning_rate=1e-3,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=15,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=processed_data_train,\n",
    "    eval_dataset=processed_data_test,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting to train...\")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
